{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f26465",
   "metadata": {},
   "source": [
    "# Evaluating Reranking\n",
    "\n",
    "In this notebook, we will:\n",
    "1. Compute the **baseline nDCG** using BM25 results.\n",
    "2. Load the trained neural reranker model.\n",
    "3. Apply the model to rerank the BM25 candidates.\n",
    "4. Compute the **new nDCG** after reranking.\n",
    "\n",
    "## Setup\n",
    "\n",
    "In this section, we configure the environment and paths needed for reranking and evaluation:\n",
    "\n",
    "1. **Parameters**  \n",
    "- `BATCH_SIZE` defines how many (query, document) pairs are processed per batch.\n",
    "- `VOCAB_SIZE` is the tokenizer vocabulary size used during training (has to be the same used during training, check `reranking_model_training.ipynb`).  \n",
    "- `MAX_Q_LENGTH` and `MAX_D_LENGTH` are the maximum sequence lengths for queries and documents, ensuring consistent padding/truncation (should be the same used during training, check `reranking_model_training.ipynb`).  \n",
    "\n",
    "2. **File paths**  \n",
    "- `CORPUS_PATH` → the full text corpus (`MEDLINE_2024_Baseline.jsonl`).  \n",
    "- `QUESTIONS_PATH` → the evaluation questions.  \n",
    "- `BM25_PATH` → top candidate documents retrieved by BM25 for each question.  \n",
    "- `MODEL_PATH` → the checkpoint of the trained neural reranker.  \n",
    "- `OUPUT_FILE` → where reranked results will be saved.  \n",
    "- `TRAIN_Q_FILE` and `TRAIN_BM25_FILE` → training data and BM25 candidates used during model training.  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a66d89f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "import ujson\n",
    "import torch\n",
    "import sys\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Add parent directory to path to import from src\n",
    "sys.path.append('..')\n",
    "\n",
    "import src.evaluation as ndcg \n",
    "from src.model import CNNInteractionBasedModel, Tokenizer, PointWiseDataset\n",
    "from src.utils import build_collate_fn, get_questions, get_all_doc_texts\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = 284342\n",
    "MAX_Q_LENGTH = 30\n",
    "MAX_D_LENGTH = 1785\n",
    "\n",
    "# Paths\n",
    "OUTPUT_DIR = '../output'\n",
    "CORPUS_PATH = \"../data/MEDLINE_2024_Baseline.jsonl\"\n",
    "QUESTIONS_PATH = \"../data/questions.jsonl\"\n",
    "BM25_PATH = \"../data/questions_bm25_ranked.jsonl\"\n",
    "MODEL_PATH = OUTPUT_DIR + \"/model/model_20251001_153857_1.pt\"\n",
    "OUPUT_FILE = OUTPUT_DIR + \"/ranked_questions.jsonl\"\n",
    "TRAIN_Q_FILE = \"../data/training_data.jsonl\"\n",
    "TRAIN_BM25_FILE = \"../data/training_data_bm25_ranked.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e0ccde",
   "metadata": {},
   "source": [
    "## Computing Ranking Metrics (BM25 Results) \n",
    "\n",
    "The system includes a script to compute the **Normalized Discounted Cumulative Gain (nDCG)** metric, which evaluates the quality of the ranked retrieval results. For this manner, execute the `nDCG.py` script.\n",
    "\n",
    "#### How nDCG Works\n",
    "\n",
    "- **DCG (Discounted Cumulative Gain)**: Measures the gain (relevance) of each document in the result list, discounted by its position in the list.\n",
    "- **IDCG (Ideal DCG)**: The maximum possible DCG achievable, obtained by an ideal ranking of documents.\n",
    "- **nDCG**: The ratio of DCG to IDCG, normalized to a value between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d787e239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID: 63f73f1b33942b094c000008, nDCG@10: 1.0000\n",
      "Query ID: 643d41e757b1c7a315000037, nDCG@10: 0.7000\n",
      "Query ID: 643c88a257b1c7a315000030, nDCG@10: 0.2824\n",
      "Query ID: 64403c4257b1c7a31500004f, nDCG@10: 0.6309\n",
      "Query ID: 6441302d57b1c7a315000056, nDCG@10: 0.6625\n",
      "Query ID: 63f042e2f36125a426000022, nDCG@10: 0.3801\n",
      "Query ID: 64184483690f196b51000038, nDCG@10: 0.8226\n",
      "Query ID: 643de76757b1c7a315000039, nDCG@10: 0.4993\n",
      "Query ID: 64403ab057b1c7a31500004d, nDCG@10: 1.0000\n",
      "Query ID: 64179139690f196b5100002f, nDCG@10: 0.0736\n",
      "Query ID: 63f02b50f36125a426000014, nDCG@10: 0.2022\n",
      "Query ID: 6411b678201352f04a000036, nDCG@10: 0.6180\n",
      "Query ID: 643bc8f957b1c7a31500002b, nDCG@10: 0.5916\n",
      "Query ID: 64403be357b1c7a31500004e, nDCG@10: 0.3155\n",
      "Query ID: 644289c457b1c7a31500005e, nDCG@10: 0.5965\n",
      "Query ID: 63f02ec1f36125a426000017, nDCG@10: 0.0000\n",
      "Query ID: 641c516d690f196b5100003f, nDCG@10: 0.6326\n",
      "Query ID: 64371c5957b1c7a31500002a, nDCG@10: 0.5972\n",
      "Query ID: 6440396957b1c7a31500004b, nDCG@10: 0.6309\n",
      "Query ID: 641791ca690f196b51000031, nDCG@10: 0.4608\n",
      "Query ID: 63eef7eff36125a42600000e, nDCG@10: 1.0000\n",
      "Query ID: 6431708a57b1c7a315000017, nDCG@10: 0.4032\n",
      "Query ID: 643c396457b1c7a31500002d, nDCG@10: 0.3806\n",
      "Query ID: 6440092d57b1c7a315000040, nDCG@10: 0.6309\n",
      "Query ID: 644291fa57b1c7a31500005f, nDCG@10: 0.4041\n",
      "Query ID: 63f741a633942b094c000009, nDCG@10: 0.9502\n",
      "Query ID: 640f8641201352f04a00002c, nDCG@10: 0.5392\n",
      "Query ID: 643c446357b1c7a31500002f, nDCG@10: 0.7973\n",
      "Query ID: 644009c557b1c7a315000041, nDCG@10: 0.0000\n",
      "Query ID: 641790a3690f196b5100002c, nDCG@10: 0.8387\n",
      "Query ID: 63f56dc533942b094c000001, nDCG@10: 0.6806\n",
      "Query ID: 643def7057b1c7a31500003a, nDCG@10: 0.4912\n",
      "Query ID: 64371a4257b1c7a315000029, nDCG@10: 0.1903\n",
      "Query ID: 6440377c57b1c7a315000049, nDCG@10: 0.0000\n",
      "Query ID: 64163568690f196b5100001b, nDCG@10: 0.0000\n",
      "Query ID: 63ee5eeaf36125a426000002, nDCG@10: 0.4208\n",
      "Query ID: 640c821c201352f04a000023, nDCG@10: 0.2621\n",
      "Query ID: 643c9b4057b1c7a315000032, nDCG@10: 0.4626\n",
      "Query ID: 6440084357b1c7a31500003e, nDCG@10: 0.0000\n",
      "Query ID: 6441057657b1c7a315000052, nDCG@10: 0.0000\n",
      "Query ID: 6402c71f201352f04a00000a, nDCG@10: 0.3164\n",
      "Query ID: 64257c9c690f196b5100004b, nDCG@10: 1.0000\n",
      "Query ID: 6429e1b857b1c7a315000008, nDCG@10: 0.6048\n",
      "Query ID: 644029f857b1c7a315000042, nDCG@10: 0.0000\n",
      "Query ID: 6442869857b1c7a31500005d, nDCG@10: 0.4247\n",
      "Query ID: 64040d73201352f04a000010, nDCG@10: 0.7602\n",
      "Query ID: 6422e7ba690f196b51000044, nDCG@10: 0.8155\n",
      "Query ID: 6429e85e57b1c7a315000009, nDCG@10: 1.0000\n",
      "Query ID: 6440360557b1c7a315000047, nDCG@10: 1.0000\n",
      "Query ID: 641794e7690f196b51000036, nDCG@10: 0.6724\n",
      "Query ID: 63ee5c78f36125a426000001, nDCG@10: 0.0000\n",
      "Query ID: 64316f8e57b1c7a315000016, nDCG@10: 0.7000\n",
      "Query ID: 6429eb8457b1c7a31500000a, nDCG@10: 0.7145\n",
      "Query ID: 6440393157b1c7a31500004a, nDCG@10: 0.5000\n",
      "Query ID: 64412c2757b1c7a315000055, nDCG@10: 0.1470\n",
      "Query ID: 64042000201352f04a000020, nDCG@10: 0.6781\n",
      "Query ID: 6415b3b4690f196b51000009, nDCG@10: 0.8240\n",
      "Query ID: 6429fad757b1c7a31500000e, nDCG@10: 0.1835\n",
      "Query ID: 64402e7757b1c7a315000044, nDCG@10: 1.0000\n",
      "Query ID: 64425ce357b1c7a315000059, nDCG@10: 0.0000\n",
      "Query ID: 63f581e933942b094c000007, nDCG@10: 0.4299\n",
      "Query ID: 641c5201690f196b51000040, nDCG@10: 0.4411\n",
      "Query ID: 643c183b57b1c7a31500002c, nDCG@10: 0.4987\n",
      "Query ID: 64402f6f57b1c7a315000045, nDCG@10: 1.0000\n",
      "Query ID: 6440f85c57b1c7a315000051, nDCG@10: 0.7345\n",
      "Query ID: 6402c3fd201352f04a000009, nDCG@10: 0.4434\n",
      "Query ID: 6431f7de57b1c7a31500001b, nDCG@10: 0.1903\n",
      "Query ID: 643ff48a57b1c7a31500003d, nDCG@10: 1.0000\n",
      "Query ID: 64410f8057b1c7a315000054, nDCG@10: 1.0000\n",
      "Query ID: 6402c0d5201352f04a000008, nDCG@10: 1.0000\n",
      "Query ID: 6419fa3d690f196b5100003c, nDCG@10: 0.5155\n",
      "Query ID: 644036cf57b1c7a315000048, nDCG@10: 1.0000\n",
      "Query ID: 643f9eeb57b1c7a31500003c, nDCG@10: 0.3533\n",
      "Query ID: 6402ba49201352f04a000004, nDCG@10: 1.0000\n",
      "Query ID: 6431f6a857b1c7a315000018, nDCG@10: 0.6676\n",
      "Query ID: 6415c252690f196b51000011, nDCG@10: 0.0000\n",
      "Query ID: 641791b9690f196b51000030, nDCG@10: 0.9400\n",
      "Query ID: 63eeed0af36125a426000007, nDCG@10: 0.4653\n",
      "Query ID: 643d3e6157b1c7a315000034, nDCG@10: 0.8580\n",
      "Query ID: 63f9ee5c33942b094c000014, nDCG@10: 1.0000\n",
      "Query ID: 644281e557b1c7a31500005b, nDCG@10: 0.0000\n",
      "Query ID: 63f03ea0f36125a426000020, nDCG@10: 0.4035\n",
      "Query ID: 6431f71057b1c7a315000019, nDCG@10: 0.8371\n",
      "Query ID: 6414c1ae690f196b51000003, nDCG@10: 1.0000\n",
      "Query ID: 64179113690f196b5100002e, nDCG@10: 0.5131\n",
      "Query ID: 64040c6b201352f04a00000f, nDCG@10: 0.8155\n",
      "Query ID: 6415b7b8690f196b5100000c, nDCG@10: 0.8029\n",
      "Query ID: 6415c9e9690f196b51000018, nDCG@10: 1.0000\n",
      "Query ID: 64178f94690f196b51000027, nDCG@10: 0.3765\n",
      "Query ID: 63f03155f36125a426000019, nDCG@10: 0.8403\n",
      "Query ID: 63f03006f36125a426000018, nDCG@10: 0.7153\n",
      "Query ID: 641ad941690f196b5100003d, nDCG@10: 0.8029\n",
      "Query ID: 642a029d57b1c7a315000011, nDCG@10: 0.7419\n",
      "Query ID: 6432fc0457b1c7a31500001f, nDCG@10: 0.0000\n",
      "Query ID: 64178edb690f196b51000025, nDCG@10: 0.9502\n",
      "Query ID: 6402bf2b201352f04a000007, nDCG@10: 1.0000\n",
      "Query ID: 641d8fd6690f196b51000041, nDCG@10: 0.5119\n",
      "Query ID: 6429d5c557b1c7a315000006, nDCG@10: 0.4694\n",
      "Query ID: 6433012b57b1c7a315000022, nDCG@10: 0.6309\n",
      "Query ID: 64179337690f196b51000034, nDCG@10: 0.8629\n",
      "\n",
      "Average nDCG@10: 0.5730\n"
     ]
    }
   ],
   "source": [
    "# Compute nDCG for the given results\n",
    "ndcg.compute_average_ndcg(\n",
    "    questions_file_path=QUESTIONS_PATH,\n",
    "    results_file_path=OUPUT_FILE,\n",
    "    k=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c31d863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNNInteractionBasedModel(\n",
       "  (embedding): Embedding(284342, 300, padding_idx=0)\n",
       "  (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (activation): ReLU()\n",
       "  (pool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trained model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "questions = get_questions(TRAIN_Q_FILE)\n",
    "documents = get_all_doc_texts(TRAIN_Q_FILE, TRAIN_BM25_FILE, CORPUS_PATH)\n",
    "tokenizer.fit(questions + documents)\n",
    "\n",
    "model = CNNInteractionBasedModel(vocab_size=VOCAB_SIZE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d363830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset for reranking\n",
    "dataset = PointWiseDataset(QUESTIONS_PATH, BM25_PATH, CORPUS_PATH, tokenizer, return_label=False)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=build_collate_fn(tokenizer, MAX_Q_LENGTH, MAX_D_LENGTH),\n",
    "    pin_memory=(device.type == \"cuda\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c146c18f",
   "metadata": {},
   "source": [
    "### Reranking with the Neural Model\n",
    "\n",
    "1. **Batch scoring**  \n",
    "- For each batch from the DataLoader, we take the tokenized queries and candidate documents.  \n",
    "- The model outputs a **relevance score** for each (query, document) pair.  \n",
    "\n",
    "2. **Collect scores per query**  \n",
    "- We store the `(document_id, score)` pairs for every query.  \n",
    "\n",
    "3. **Sort candidates**  \n",
    "- For each query, we sort the candidate documents in descending order of model score.  \n",
    "- This step produces the final reranked list of documents for each query.  \n",
    "\n",
    "4. **Save results**  \n",
    "- The results are saved in a JSONL file with the format:\n",
    "   ```json\n",
    "   {\n",
    "      \"query_id\": \"...\",\n",
    "      \"retrieved_documents\": [\"doc1\", \"doc2\", \"doc3\", ...]\n",
    "   }\n",
    "   ```\n",
    "- This keeps the same structure as the BM25 file, making it easy to compare baseline vs reranked performance.  \n",
    "\n",
    "This reranking step does not retrieve new documents — it only **reorders the BM25 shortlist** according to the learned neural model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08c5a9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked results saved to: ../output/ranked_questions_model.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Run reranking\n",
    "reranked_results = {}\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        q_tokens = batch[\"question_token_ids\"].to(device)\n",
    "        d_tokens = batch[\"document_token_ids\"].to(device)\n",
    "        qids = batch[\"query_ids\"]\n",
    "        dids = batch[\"document_ids\"]\n",
    "\n",
    "        scores = model(q_tokens, d_tokens)\n",
    "\n",
    "        for i, qid in enumerate(qids):\n",
    "            if qid not in reranked_results:\n",
    "                reranked_results[qid] = []\n",
    "            reranked_results[qid].append((dids[i], float(scores[i])))\n",
    "\n",
    "# sort by model score\n",
    "for qid, doc_scores in reranked_results.items():\n",
    "    reranked_results[qid] = [doc for doc, _ in sorted(doc_scores, key=lambda x: x[1], reverse=True)]\n",
    "\n",
    "output_file = os.path.join(OUTPUT_DIR, 'ranked_questions_model.jsonl')\n",
    "with open(output_file, 'w') as f:\n",
    "    for qid, docs in reranked_results.items():\n",
    "        entry = {\n",
    "            \"query_id\": qid,\n",
    "            \"retrieved_documents\": docs\n",
    "        }\n",
    "        f.write(ujson.dumps(entry) + '\\n')\n",
    "\n",
    "print(f\"Reranked results saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0223c021",
   "metadata": {},
   "source": [
    "## Evaluate Retrieved Documents (Model Reranking)\n",
    "\n",
    "Here we compute the **Normalized Discounted Cumulative Gain (nDCG)** metric, which evaluates the quality of the ranked retrieval results after model reranking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99a12933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked nDCG@10 (Model)\n",
      "Query ID: 63f73f1b33942b094c000008, nDCG@10: 0.4307\n",
      "Query ID: 643d41e757b1c7a315000037, nDCG@10: 0.0000\n",
      "Query ID: 643c88a257b1c7a315000030, nDCG@10: 0.0000\n",
      "Query ID: 64403c4257b1c7a31500004f, nDCG@10: 0.6309\n",
      "Query ID: 6441302d57b1c7a315000056, nDCG@10: 0.0000\n",
      "Query ID: 63f042e2f36125a426000022, nDCG@10: 0.0000\n",
      "Query ID: 64184483690f196b51000038, nDCG@10: 0.4524\n",
      "Query ID: 643de76757b1c7a315000039, nDCG@10: 0.4903\n",
      "Query ID: 64403ab057b1c7a31500004d, nDCG@10: 0.0000\n",
      "Query ID: 64179139690f196b5100002f, nDCG@10: 0.0000\n",
      "Query ID: 63f02b50f36125a426000014, nDCG@10: 0.0000\n",
      "Query ID: 6411b678201352f04a000036, nDCG@10: 0.2581\n",
      "Query ID: 643bc8f957b1c7a31500002b, nDCG@10: 0.1009\n",
      "Query ID: 64403be357b1c7a31500004e, nDCG@10: 0.0000\n",
      "Query ID: 644289c457b1c7a31500005e, nDCG@10: 0.0000\n",
      "Query ID: 63f02ec1f36125a426000017, nDCG@10: 0.0000\n",
      "Query ID: 641c516d690f196b5100003f, nDCG@10: 0.1774\n",
      "Query ID: 64371c5957b1c7a31500002a, nDCG@10: 0.3806\n",
      "Query ID: 6440396957b1c7a31500004b, nDCG@10: 0.0000\n",
      "Query ID: 641791ca690f196b51000031, nDCG@10: 0.0000\n",
      "Query ID: 63eef7eff36125a42600000e, nDCG@10: 0.0000\n",
      "Query ID: 6431708a57b1c7a315000017, nDCG@10: 0.0000\n",
      "Query ID: 643c396457b1c7a31500002d, nDCG@10: 0.0000\n",
      "Query ID: 6440092d57b1c7a315000040, nDCG@10: 0.0000\n",
      "Query ID: 644291fa57b1c7a31500005f, nDCG@10: 0.1524\n",
      "Query ID: 63f741a633942b094c000009, nDCG@10: 0.0000\n",
      "Query ID: 640f8641201352f04a00002c, nDCG@10: 0.0600\n",
      "Query ID: 643c446357b1c7a31500002f, nDCG@10: 0.2698\n",
      "Query ID: 644009c557b1c7a315000041, nDCG@10: 0.0000\n",
      "Query ID: 641790a3690f196b5100002c, nDCG@10: 0.0000\n",
      "Query ID: 63f56dc533942b094c000001, nDCG@10: 0.4988\n",
      "Query ID: 643def7057b1c7a31500003a, nDCG@10: 0.2966\n",
      "Query ID: 64371a4257b1c7a315000029, nDCG@10: 0.2504\n",
      "Query ID: 6440377c57b1c7a315000049, nDCG@10: 0.0000\n",
      "Query ID: 64163568690f196b5100001b, nDCG@10: 0.0000\n",
      "Query ID: 63ee5eeaf36125a426000002, nDCG@10: 0.1008\n",
      "Query ID: 640c821c201352f04a000023, nDCG@10: 0.2581\n",
      "Query ID: 643c9b4057b1c7a315000032, nDCG@10: 0.0952\n",
      "Query ID: 6440084357b1c7a31500003e, nDCG@10: 0.0000\n",
      "Query ID: 6441057657b1c7a315000052, nDCG@10: 0.0000\n",
      "Query ID: 6402c71f201352f04a00000a, nDCG@10: 0.0000\n",
      "Query ID: 64257c9c690f196b5100004b, nDCG@10: 0.0000\n",
      "Query ID: 6429e1b857b1c7a315000008, nDCG@10: 0.1524\n",
      "Query ID: 644029f857b1c7a315000042, nDCG@10: 0.0000\n",
      "Query ID: 6442869857b1c7a31500005d, nDCG@10: 0.2152\n",
      "Query ID: 64040d73201352f04a000010, nDCG@10: 0.0000\n",
      "Query ID: 6422e7ba690f196b51000044, nDCG@10: 0.0000\n",
      "Query ID: 6429e85e57b1c7a315000009, nDCG@10: 0.3305\n",
      "Query ID: 6440360557b1c7a315000047, nDCG@10: 1.0000\n",
      "Query ID: 641794e7690f196b51000036, nDCG@10: 0.0000\n",
      "Query ID: 63ee5c78f36125a426000001, nDCG@10: 0.0000\n",
      "Query ID: 64316f8e57b1c7a315000016, nDCG@10: 0.7814\n",
      "Query ID: 6429eb8457b1c7a31500000a, nDCG@10: 0.3401\n",
      "Query ID: 6440393157b1c7a31500004a, nDCG@10: 0.0000\n",
      "Query ID: 64412c2757b1c7a315000055, nDCG@10: 0.0000\n",
      "Query ID: 64042000201352f04a000020, nDCG@10: 0.0000\n",
      "Query ID: 6415b3b4690f196b51000009, nDCG@10: 0.2323\n",
      "Query ID: 6429fad757b1c7a31500000e, nDCG@10: 0.0000\n",
      "Query ID: 64402e7757b1c7a315000044, nDCG@10: 0.0000\n",
      "Query ID: 64425ce357b1c7a315000059, nDCG@10: 0.0000\n",
      "Query ID: 63f581e933942b094c000007, nDCG@10: 0.0000\n",
      "Query ID: 641c5201690f196b51000040, nDCG@10: 0.0000\n",
      "Query ID: 643c183b57b1c7a31500002c, nDCG@10: 0.3738\n",
      "Query ID: 64402f6f57b1c7a315000045, nDCG@10: 0.0000\n",
      "Query ID: 6440f85c57b1c7a315000051, nDCG@10: 0.0952\n",
      "Query ID: 6402c3fd201352f04a000009, nDCG@10: 0.6667\n",
      "Query ID: 6431f7de57b1c7a31500001b, nDCG@10: 0.0000\n",
      "Query ID: 643ff48a57b1c7a31500003d, nDCG@10: 0.0000\n",
      "Query ID: 64410f8057b1c7a315000054, nDCG@10: 0.0000\n",
      "Query ID: 6402c0d5201352f04a000008, nDCG@10: 0.3333\n",
      "Query ID: 6419fa3d690f196b5100003c, nDCG@10: 0.0000\n",
      "Query ID: 644036cf57b1c7a315000048, nDCG@10: 0.6309\n",
      "Query ID: 643f9eeb57b1c7a31500003c, nDCG@10: 0.2627\n",
      "Query ID: 6402ba49201352f04a000004, nDCG@10: 0.0000\n",
      "Query ID: 6431f6a857b1c7a315000018, nDCG@10: 0.0000\n",
      "Query ID: 6415c252690f196b51000011, nDCG@10: 0.0000\n",
      "Query ID: 641791b9690f196b51000030, nDCG@10: 0.2723\n",
      "Query ID: 63eeed0af36125a426000007, nDCG@10: 0.0000\n",
      "Query ID: 643d3e6157b1c7a315000034, nDCG@10: 0.1371\n",
      "Query ID: 63f9ee5c33942b094c000014, nDCG@10: 1.0000\n",
      "Query ID: 644281e557b1c7a31500005b, nDCG@10: 0.0000\n",
      "Query ID: 63f03ea0f36125a426000020, nDCG@10: 0.1354\n",
      "Query ID: 6431f71057b1c7a315000019, nDCG@10: 0.2408\n",
      "Query ID: 6414c1ae690f196b51000003, nDCG@10: 0.0000\n",
      "Query ID: 64179113690f196b5100002e, nDCG@10: 0.1552\n",
      "Query ID: 64040c6b201352f04a00000f, nDCG@10: 0.0000\n",
      "Query ID: 6415b7b8690f196b5100000c, nDCG@10: 0.0000\n",
      "Query ID: 6415c9e9690f196b51000018, nDCG@10: 0.0000\n",
      "Query ID: 64178f94690f196b51000027, nDCG@10: 0.1763\n",
      "Query ID: 63f03155f36125a426000019, nDCG@10: 0.0000\n",
      "Query ID: 63f03006f36125a426000018, nDCG@10: 0.0000\n",
      "Query ID: 641ad941690f196b5100003d, nDCG@10: 0.0634\n",
      "Query ID: 642a029d57b1c7a315000011, nDCG@10: 0.4530\n",
      "Query ID: 6432fc0457b1c7a31500001f, nDCG@10: 0.0000\n",
      "Query ID: 64178edb690f196b51000025, nDCG@10: 0.4374\n",
      "Query ID: 6402bf2b201352f04a000007, nDCG@10: 0.0000\n",
      "Query ID: 641d8fd6690f196b51000041, nDCG@10: 0.1078\n",
      "Query ID: 6429d5c557b1c7a315000006, nDCG@10: 0.1201\n",
      "Query ID: 6433012b57b1c7a315000022, nDCG@10: 0.3010\n",
      "Query ID: 64179337690f196b51000034, nDCG@10: 0.0000\n",
      "\n",
      "Average nDCG@10: 0.1392\n"
     ]
    }
   ],
   "source": [
    "print(f\"Reranked nDCG@10 (Model)\")\n",
    "\n",
    "# Compute nDCG after reranking\n",
    "ndcg.compute_average_ndcg(\n",
    "    questions_file_path=QUESTIONS_PATH,\n",
    "    results_file_path=output_file,\n",
    "    k=10\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
